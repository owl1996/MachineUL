{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='mps'), 12)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from utils import loaders_by_classes, filter_loaders, balance, balanced_batch_size, submodel, get_activations\n",
    "from classNet import ConvNet # for torch load\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "device, num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all_class = torch.load('./models/all_class.pth', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.25, inplace=False)\n",
       "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_num = 7\n",
    "class_name = '7 - seven'\n",
    "model = submodel(model_all_class, class_num)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize((0,), (1,))  # Normalize images\n",
    "])\n",
    "\n",
    "train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loaders = loaders_by_classes(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loaders = loaders_by_classes(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0 - zero': <torch.utils.data.dataloader.DataLoader at 0x16a283fe0>,\n",
       " '1 - one': <torch.utils.data.dataloader.DataLoader at 0x16a1c7fb0>,\n",
       " '2 - two': <torch.utils.data.dataloader.DataLoader at 0x13fd58e00>,\n",
       " '3 - three': <torch.utils.data.dataloader.DataLoader at 0x16a244fb0>,\n",
       " '4 - four': <torch.utils.data.dataloader.DataLoader at 0x16a0ba0c0>,\n",
       " '5 - five': <torch.utils.data.dataloader.DataLoader at 0x11a9c2390>,\n",
       " '6 - six': <torch.utils.data.dataloader.DataLoader at 0x16a2b5490>,\n",
       " '7 - seven': <torch.utils.data.dataloader.DataLoader at 0x16a2b5370>,\n",
       " '8 - eight': <torch.utils.data.dataloader.DataLoader at 0x16a2b5340>,\n",
       " '9 - nine': <torch.utils.data.dataloader.DataLoader at 0x16a2b5550>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders = train_loaders\n",
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "969"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blcd_batch_size = int(batch_size * balanced_batch_size(loaders, class_name))\n",
    "blcd_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "forget_loader = loaders[class_name]\n",
    "retain_loader = filter_loaders(loaders, class_name, blcd_batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "retain_input = next(iter(retain_loader))\n",
    "r_input_tensor, r_label_tensor = retain_input[0].to(device), retain_input[1].to(device)\n",
    "forget_input = next(iter(forget_loader))\n",
    "f_input_tensor, f_label_tensor = forget_input[0].to(device), forget_input[1].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_softmax(model, n_batch = 10):\n",
    "    \"\"\"\n",
    "    Get rpz of forget wrt to retain\n",
    "    Just at the init\n",
    "    \"\"\"\n",
    "    softmax = 0\n",
    "    for i_batch in range(n_batch):\n",
    "        input_tensor = next(iter(forget_loader))\n",
    "        softmax += torch.exp(model(input_tensor[0].to(device)))\n",
    "    softmax = softmax / n_batch\n",
    "    return softmax.mean(dim=0)\n",
    "\n",
    "def convex_target(softmax, activations, labels):\n",
    "    \"\"\"\n",
    "    softmax : from forget rpz wrt to retain\n",
    "    activations : residues of retain\n",
    "    \"\"\"\n",
    "    target = 0\n",
    "    activations_dict = {}\n",
    "    for idx, _label in enumerate(labels):\n",
    "        label = int(_label.item())\n",
    "        if label not in activations_dict.keys():\n",
    "            activations_dict[label] = {}\n",
    "            activations_dict[label]['activation'] = activations[idx, :].clone()\n",
    "            activations_dict[label]['count'] = 1\n",
    "        else:\n",
    "            activations_dict[label]['activation'] += activations[idx, :]\n",
    "            activations_dict[label]['count'] += 1\n",
    "\n",
    "    for key, dval in activations_dict.items():\n",
    "        ikey = key - 1 * (key > class_num)\n",
    "        target += softmax[ikey] * dval['activation'] / dval['count']\n",
    "    \n",
    "    return target\n",
    "\n",
    "def masked_grads(forget_grads, retain_grads):\n",
    "    m_grads = []\n",
    "    for idx_param, f_grad in enumerate(forget_grads):\n",
    "        r_grad = retain_grads[idx_param]\n",
    "        mask = f_grad * r_grad > 0\n",
    "        m_grad = mask * f_grad * torch.abs(r_grad)\n",
    "        m_grads.append(m_grad)\n",
    "    return m_grads\n",
    "\n",
    "def update_param(model, forget_grads, retain_grads):\n",
    "    m_grads = masked_grads(forget_grads, retain_grads)\n",
    "    max_perc_param = 0.\n",
    "    for idx_param, param in enumerate(model.parameters()):\n",
    "        param.grad = m_grads[idx_param]\n",
    "        perc_param = 100 * torch.sum(param.grad > 0)/torch.tensor(param.size()).prod()\n",
    "        if perc_param > max_perc_param:\n",
    "            max_perc_param = perc_param\n",
    "    return max_perc_param\n",
    "\n",
    "def get_grads(model, softmax, forget_input, retain_input, device=device, verbose=False):\n",
    "    r_input_tensor, r_label_tensor = retain_input[0].to(device), retain_input[1].to(device)\n",
    "    f_input_tensor, _ = forget_input[0].to(device), forget_input[1].to(device)\n",
    "\n",
    "    # get r_grads\n",
    "    model.zero_grad()\n",
    "    r_input_tensor.requires_grad = True\n",
    "    retain_dict = get_activations(model, r_input_tensor, -1, verbose=verbose)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    loss = criterion(retain_dict['output'], r_label_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    r_grads = []\n",
    "    for param in model.parameters():\n",
    "        r_grads.append(param.grad)\n",
    "\n",
    "    # get f_grads\n",
    "    model.zero_grad()\n",
    "    f_input_tensor.requires_grad = True\n",
    "    forget_dict = get_activations(model, f_input_tensor, -1, verbose=verbose)\n",
    "\n",
    "    r_activations = retain_dict['activations'].detach()\n",
    "    target = convex_target(softmax, r_activations, r_label_tensor)\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    loss = criterion(torch.mean(forget_dict['activations'], dim=0), target)\n",
    "    loss.backward()\n",
    "\n",
    "    f_grads = []\n",
    "    for param in model.parameters():\n",
    "        f_grads.append(param.grad)\n",
    "    \n",
    "    return f_grads, r_grads\n",
    "\n",
    "def unlearn_step(model, softmax, forget_input, retain_input, optimizer, device=device):\n",
    "    optimizer.zero_grad()\n",
    "    f_grads, r_grads = get_grads(model, softmax, forget_input, retain_input, verbose=False)\n",
    "    max_perc_param = update_param(model, f_grads, r_grads)\n",
    "    optimizer.step()\n",
    "    return max_perc_param\n",
    "\n",
    "def untrain(model, softmax, device, forget_loader, retain_loader, optimizer, n_step=None):\n",
    "    model.train()\n",
    "    forget_iter_loader = iter(forget_loader)\n",
    "    for batch_idx, retain_input in enumerate(retain_loader):\n",
    "        try:\n",
    "            forget_input = next(forget_iter_loader)\n",
    "        except:\n",
    "            forget_iter_loader = iter(forget_loader)\n",
    "            forget_input = next(forget_iter_loader)\n",
    "        max_perc_param = unlearn_step(model, softmax, forget_input, retain_input, optimizer, device=device)\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'{batch_idx} / {len(retain_loader)}')\n",
    "        if batch_idx == n_step:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = get_softmax(model).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4306, device='mps:0')\n",
      "0 / 56\n",
      "tensor(3.1250, device='mps:0')\n",
      "tensor(1.7361, device='mps:0')\n",
      "tensor(1.3889, device='mps:0')\n",
      "tensor(1.7361, device='mps:0')\n",
      "tensor(1.0417, device='mps:0')\n",
      "tensor(0.6944, device='mps:0')\n",
      "tensor(2.0833, device='mps:0')\n",
      "tensor(1.0417, device='mps:0')\n",
      "tensor(2.0833, device='mps:0')\n",
      "tensor(1.7361, device='mps:0')\n",
      "10 / 56\n",
      "tensor(0.3472, device='mps:0')\n",
      "tensor(0.6944, device='mps:0')\n",
      "tensor(0.3472, device='mps:0')\n",
      "tensor(0.6944, device='mps:0')\n",
      "tensor(0.3472, device='mps:0')\n",
      "tensor(0.6944, device='mps:0')\n",
      "tensor(0.6944, device='mps:0')\n",
      "tensor(1.3889, device='mps:0')\n",
      "tensor(1.0417, device='mps:0')\n",
      "tensor(1.0417, device='mps:0')\n",
      "20 / 56\n",
      "tensor(0.6944, device='mps:0')\n",
      "tensor(0.6944, device='mps:0')\n",
      "tensor(0.6944, device='mps:0')\n",
      "tensor(1.0417, device='mps:0')\n",
      "tensor(1.0417, device='mps:0')\n",
      "tensor(0.6944, device='mps:0')\n",
      "0.0\n",
      "0.0\n",
      "tensor(0.6944, device='mps:0')\n",
      "tensor(0.6944, device='mps:0')\n",
      "30 / 56\n",
      "tensor(0.3472, device='mps:0')\n",
      "0.0\n",
      "0.0\n",
      "tensor(0.6944, device='mps:0')\n",
      "tensor(0.6944, device='mps:0')\n",
      "tensor(1.0417, device='mps:0')\n",
      "tensor(1.7361, device='mps:0')\n",
      "tensor(2.0833, device='mps:0')\n",
      "tensor(2.4306, device='mps:0')\n",
      "tensor(3.1250, device='mps:0')\n",
      "40 / 56\n",
      "tensor(3.8194, device='mps:0')\n",
      "tensor(4.5139, device='mps:0')\n",
      "tensor(3.1250, device='mps:0')\n",
      "tensor(3.4722, device='mps:0')\n",
      "tensor(2.4306, device='mps:0')\n",
      "tensor(2.4306, device='mps:0')\n",
      "tensor(2.0833, device='mps:0')\n",
      "tensor(1.7361, device='mps:0')\n",
      "tensor(2.0833, device='mps:0')\n",
      "tensor(2.4306, device='mps:0')\n",
      "50 / 56\n",
      "tensor(2.7778, device='mps:0')\n",
      "tensor(2.4306, device='mps:0')\n",
      "tensor(2.7778, device='mps:0')\n",
      "tensor(2.7778, device='mps:0')\n",
      "tensor(1.7361, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "untrain(model, softmax, device, forget_loader, retain_loader, optimizer, n_step = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.5790e-03, 1.1933e-01, 1.7121e-01, 2.6863e-01, 5.7375e-02, 4.8021e-03,\n",
       "        1.7888e-05, 7.3697e-03, 3.6768e-01], device='mps:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5358e-04, 1.1746e-05, 3.6112e-02, 1.6826e-01, 1.1612e-01, 1.1124e-01,\n",
       "        6.6318e-03, 4.7810e-04, 5.6069e-01], device='mps:0',\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_softmax(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9537, device='mps:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "loss = criterion(model(r_input_tensor), r_label_tensor)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

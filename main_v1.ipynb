{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='mps'), 12)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from utils import loaders_by_classes, filter_loaders, balance, balanced_batch_size, submodel, get_activations\n",
    "from classNet import ConvNet # for torch load\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "device, num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all_class = torch.load('./models/all_class.pth', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.25, inplace=False)\n",
       "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_num = 7\n",
    "class_name = '7 - seven'\n",
    "model = submodel(model_all_class, class_num)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize((0,), (1,))  # Normalize images\n",
    "])\n",
    "\n",
    "train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loaders = loaders_by_classes(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loaders = loaders_by_classes(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0 - zero': <torch.utils.data.dataloader.DataLoader at 0x32a243740>,\n",
       " '1 - one': <torch.utils.data.dataloader.DataLoader at 0x32a2878f0>,\n",
       " '2 - two': <torch.utils.data.dataloader.DataLoader at 0x32a09a720>,\n",
       " '3 - three': <torch.utils.data.dataloader.DataLoader at 0x1061eb290>,\n",
       " '4 - four': <torch.utils.data.dataloader.DataLoader at 0x32a2b4350>,\n",
       " '5 - five': <torch.utils.data.dataloader.DataLoader at 0x32a2b4770>,\n",
       " '6 - six': <torch.utils.data.dataloader.DataLoader at 0x32a2b5040>,\n",
       " '7 - seven': <torch.utils.data.dataloader.DataLoader at 0x32a2b5100>,\n",
       " '8 - eight': <torch.utils.data.dataloader.DataLoader at 0x32a2b51c0>,\n",
       " '9 - nine': <torch.utils.data.dataloader.DataLoader at 0x32a2b5280>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders = train_loaders\n",
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blcd_batch_size = int(batch_size * balanced_batch_size(loaders, class_name))\n",
    "blcd_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forget_loader = loaders[class_name]\n",
    "retain_loader = filter_loaders(loaders, class_name, blcd_batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retain_input = next(iter(retain_loader))\n",
    "r_input_tensor, r_label_tensor = retain_input[0].to(device), retain_input[1].to(device)\n",
    "forget_input = next(iter(forget_loader))\n",
    "f_input_tensor, f_label_tensor = forget_input[0].to(device), forget_input[1].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_softmax(model, n_batch = 10):\n",
    "    \"\"\"\n",
    "    Get rpz of forget wrt to retain\n",
    "    Just at the init\n",
    "    \"\"\"\n",
    "    softmax = 0\n",
    "    for i_batch in range(n_batch):\n",
    "        input_tensor = next(iter(forget_loader))\n",
    "        softmax += torch.exp(model(input_tensor[0].to(device)))\n",
    "    softmax = softmax / n_batch\n",
    "    return softmax.mean(dim=0)\n",
    "\n",
    "def convex_target(softmax, activations, labels):\n",
    "    \"\"\"\n",
    "    softmax : from forget rpz wrt to retain\n",
    "    activations : residues of retain\n",
    "    \"\"\"\n",
    "    target = 0\n",
    "    activations_dict = {}\n",
    "    for idx, _label in enumerate(labels):\n",
    "        label = int(_label.item())\n",
    "        if label not in activations_dict.keys():\n",
    "            activations_dict[label] = {}\n",
    "            activations_dict[label]['activation'] = activations[idx, :].clone()\n",
    "            activations_dict[label]['count'] = 1\n",
    "        else:\n",
    "            activations_dict[label]['activation'] += activations[idx, :]\n",
    "            activations_dict[label]['count'] += 1\n",
    "\n",
    "    for key, dval in activations_dict.items():\n",
    "        ikey = key - 1 * (key > class_num)\n",
    "        target += softmax[ikey] * dval['activation'] / dval['count']\n",
    "    \n",
    "    return target\n",
    "\n",
    "def masked_grads(forget_grads, retain_grads):\n",
    "    m_grads = []\n",
    "    for idx_param, f_grad in enumerate(forget_grads):\n",
    "        r_grad = retain_grads[idx_param]\n",
    "        mask = f_grad * r_grad > 0\n",
    "        m_grad = mask * f_grad * torch.abs(r_grad)\n",
    "        m_grads.append(m_grad)\n",
    "    return m_grads\n",
    "\n",
    "def update_param(model, forget_grads, retain_grads):\n",
    "    m_grads = masked_grads(forget_grads, retain_grads)\n",
    "    for idx_param, param in enumerate(model.parameters()):\n",
    "        \n",
    "        param.grad = m_grads[idx_param]\n",
    "        if idx_param == 4:\n",
    "            print(100 * torch.sum(param.grad > 0)/torch.tensor(param.size()).prod())\n",
    "\n",
    "# get grads\n",
    "def get_grads(model, softmax, forget_input, retain_input, device=device, verbose=False):\n",
    "    r_input_tensor, r_label_tensor = retain_input[0].to(device), retain_input[1].to(device)\n",
    "    f_input_tensor, _ = forget_input[0].to(device), forget_input[1].to(device)\n",
    "\n",
    "    # get r_grads\n",
    "    model.zero_grad()\n",
    "    r_input_tensor.requires_grad = True\n",
    "    retain_dict = get_activations(model, r_input_tensor, -1, verbose=verbose)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    loss = criterion(retain_dict['output'], r_label_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    r_grads = []\n",
    "    for param in model.parameters():\n",
    "        r_grads.append(param.grad)\n",
    "\n",
    "    # get f_grads\n",
    "    model.zero_grad()\n",
    "    f_input_tensor.requires_grad = True\n",
    "    forget_dict = get_activations(model, f_input_tensor, -1, verbose=verbose)\n",
    "\n",
    "    r_activations = retain_dict['activations'].detach()\n",
    "    target = convex_target(softmax, r_activations, r_label_tensor)\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    loss = criterion(torch.mean(forget_dict['activations'], dim=0), target)\n",
    "    loss.backward()\n",
    "\n",
    "    f_grads = []\n",
    "    for param in model.parameters():\n",
    "        f_grads.append(param.grad)\n",
    "    \n",
    "    return f_grads, r_grads\n",
    "\n",
    "def unlearn_step(model, softmax, forget_input, retain_input, optimizer, device=device):\n",
    "    optimizer.zero_grad()\n",
    "    f_grads, r_grads = get_grads(model, softmax, forget_input, retain_input, verbose=False)\n",
    "    update_param(model, f_grads, r_grads)\n",
    "    optimizer.step()\n",
    "\n",
    "def untrain(model, softmax, device, forget_loader, retain_loader, optimizer, n_step = None):\n",
    "    model.train()\n",
    "    forget_iter_loader = iter(forget_loader)\n",
    "    for batch_idx, retain_input in enumerate(retain_loader):\n",
    "        try:\n",
    "            forget_input = next(forget_iter_loader)\n",
    "        except:\n",
    "            forget_iter_loader = iter(forget_loader)\n",
    "            forget_input = next(forget_iter_loader)\n",
    "        unlearn_step(model, softmax, forget_input, retain_input, optimizer, device=device)\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'{batch_idx} / {len(retain_loader)}')\n",
    "        if batch_idx == n_step:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = get_softmax(model).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2112, device='mps:0')\n",
      "0 / 112\n",
      "tensor(0.9482, device='mps:0')\n",
      "tensor(0.5989, device='mps:0')\n",
      "tensor(3.3980, device='mps:0')\n",
      "tensor(1.0715, device='mps:0')\n",
      "tensor(0.8919, device='mps:0')\n",
      "tensor(0.6427, device='mps:0')\n",
      "tensor(7.6590, device='mps:0')\n",
      "tensor(2.6472, device='mps:0')\n",
      "tensor(9.4986, device='mps:0')\n",
      "tensor(3.4720, device='mps:0')\n",
      "10 / 112\n",
      "tensor(7.8137, device='mps:0')\n",
      "tensor(0.9940, device='mps:0')\n",
      "tensor(0.9950, device='mps:0')\n",
      "tensor(2.4623, device='mps:0')\n",
      "tensor(0.6285, device='mps:0')\n",
      "tensor(1.0939, device='mps:0')\n",
      "tensor(2.5032, device='mps:0')\n",
      "tensor(0.7102, device='mps:0')\n",
      "tensor(1.3019, device='mps:0')\n",
      "tensor(0.7197, device='mps:0')\n",
      "20 / 112\n",
      "tensor(0.8998, device='mps:0')\n",
      "tensor(1.1367, device='mps:0')\n",
      "tensor(3.2466, device='mps:0')\n",
      "tensor(1.0565, device='mps:0')\n",
      "tensor(1.3091, device='mps:0')\n",
      "tensor(1.1813, device='mps:0')\n",
      "tensor(5.7998, device='mps:0')\n",
      "tensor(1.8512, device='mps:0')\n",
      "tensor(8.2425, device='mps:0')\n",
      "tensor(0.8732, device='mps:0')\n",
      "30 / 112\n",
      "tensor(7.2126, device='mps:0')\n",
      "tensor(3.3338, device='mps:0')\n",
      "tensor(1.6420, device='mps:0')\n",
      "tensor(0.4556, device='mps:0')\n",
      "tensor(7.0375, device='mps:0')\n",
      "tensor(6.3384, device='mps:0')\n",
      "tensor(0.7621, device='mps:0')\n",
      "tensor(3.3923, device='mps:0')\n",
      "tensor(0.9649, device='mps:0')\n",
      "tensor(0.7476, device='mps:0')\n",
      "40 / 112\n",
      "tensor(1.4484, device='mps:0')\n",
      "tensor(2.7710, device='mps:0')\n",
      "tensor(8.4463, device='mps:0')\n",
      "tensor(9.3501, device='mps:0')\n",
      "tensor(7.1224, device='mps:0')\n",
      "tensor(8.1857, device='mps:0')\n",
      "tensor(5.3111, device='mps:0')\n",
      "tensor(8.5180, device='mps:0')\n",
      "tensor(7.7918, device='mps:0')\n",
      "tensor(1.4359, device='mps:0')\n",
      "50 / 112\n",
      "tensor(5.0041, device='mps:0')\n",
      "tensor(5.3948, device='mps:0')\n",
      "tensor(4.8928, device='mps:0')\n",
      "tensor(7.3569, device='mps:0')\n",
      "tensor(7.3302, device='mps:0')\n",
      "tensor(0.6133, device='mps:0')\n",
      "tensor(0.7785, device='mps:0')\n",
      "tensor(5.4623, device='mps:0')\n",
      "tensor(0.5842, device='mps:0')\n",
      "tensor(1.6183, device='mps:0')\n",
      "60 / 112\n",
      "tensor(0.7857, device='mps:0')\n",
      "tensor(1.8734, device='mps:0')\n",
      "tensor(1.4265, device='mps:0')\n",
      "tensor(0.5299, device='mps:0')\n",
      "tensor(0.7543, device='mps:0')\n",
      "tensor(0.6557, device='mps:0')\n",
      "tensor(7.1909, device='mps:0')\n",
      "tensor(5.9832, device='mps:0')\n",
      "tensor(6.7445, device='mps:0')\n",
      "tensor(0.7035, device='mps:0')\n",
      "70 / 112\n",
      "tensor(6.3536, device='mps:0')\n",
      "tensor(6.8925, device='mps:0')\n",
      "tensor(0.9825, device='mps:0')\n",
      "tensor(2.1233, device='mps:0')\n",
      "tensor(0.7663, device='mps:0')\n",
      "tensor(6.4204, device='mps:0')\n",
      "tensor(0.7499, device='mps:0')\n",
      "tensor(5.1887, device='mps:0')\n",
      "tensor(0.6853, device='mps:0')\n",
      "tensor(5.5059, device='mps:0')\n",
      "80 / 112\n",
      "tensor(6.2640, device='mps:0')\n",
      "tensor(0.8196, device='mps:0')\n",
      "tensor(1.0710, device='mps:0')\n",
      "tensor(6.2694, device='mps:0')\n",
      "tensor(0.4963, device='mps:0')\n",
      "tensor(5.9917, device='mps:0')\n",
      "tensor(0.8131, device='mps:0')\n",
      "tensor(6.9059, device='mps:0')\n",
      "tensor(3.6972, device='mps:0')\n",
      "tensor(1.3084, device='mps:0')\n",
      "90 / 112\n",
      "tensor(1.2092, device='mps:0')\n",
      "tensor(5.0492, device='mps:0')\n",
      "tensor(6.1670, device='mps:0')\n",
      "tensor(1.1126, device='mps:0')\n",
      "tensor(1.6773, device='mps:0')\n",
      "tensor(1.5079, device='mps:0')\n",
      "tensor(0.9738, device='mps:0')\n",
      "tensor(1.3206, device='mps:0')\n",
      "tensor(2.6514, device='mps:0')\n",
      "tensor(6.4809, device='mps:0')\n",
      "100 / 112\n",
      "tensor(1.8654, device='mps:0')\n",
      "tensor(1.2650, device='mps:0')\n",
      "tensor(6.7091, device='mps:0')\n",
      "tensor(1.7025, device='mps:0')\n",
      "tensor(6.9107, device='mps:0')\n",
      "tensor(6.9266, device='mps:0')\n",
      "tensor(1.5503, device='mps:0')\n",
      "tensor(0.8904, device='mps:0')\n",
      "tensor(2.5338, device='mps:0')\n",
      "tensor(0.7294, device='mps:0')\n",
      "110 / 112\n",
      "tensor(2.5667, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "untrain(model, softmax, device, forget_loader, retain_loader, optimizer, n_step = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8271, device='mps:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "loss = criterion(model(r_input_tensor), r_label_tensor)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

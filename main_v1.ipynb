{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='mps'), 12)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from utils import loaders_by_classes, filter_loaders, balance, balanced_batch_size, submodel, get_activations\n",
    "from classNet import ConvNet # for torch load\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "device, num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all_class = torch.load('./models/all_class.pth', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.25, inplace=False)\n",
       "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_num = 7\n",
    "class_name = '7 - seven'\n",
    "model = submodel(model_all_class, class_num)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize((0,), (1,))  # Normalize images\n",
    "])\n",
    "\n",
    "train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loaders = loaders_by_classes(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loaders = loaders_by_classes(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0 - zero': <torch.utils.data.dataloader.DataLoader at 0x106be9850>,\n",
       " '1 - one': <torch.utils.data.dataloader.DataLoader at 0x106bc2750>,\n",
       " '2 - two': <torch.utils.data.dataloader.DataLoader at 0x17d8f6a20>,\n",
       " '3 - three': <torch.utils.data.dataloader.DataLoader at 0x17de87830>,\n",
       " '4 - four': <torch.utils.data.dataloader.DataLoader at 0x17de877a0>,\n",
       " '5 - five': <torch.utils.data.dataloader.DataLoader at 0x17deb0dd0>,\n",
       " '6 - six': <torch.utils.data.dataloader.DataLoader at 0x17deb0620>,\n",
       " '7 - seven': <torch.utils.data.dataloader.DataLoader at 0x17deb0f20>,\n",
       " '8 - eight': <torch.utils.data.dataloader.DataLoader at 0x17deb1010>,\n",
       " '9 - nine': <torch.utils.data.dataloader.DataLoader at 0x17deb10d0>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders = train_loaders\n",
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blcd_batch_size = int(batch_size * balanced_batch_size(loaders, class_name))\n",
    "blcd_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "forget_loader = loaders[class_name]\n",
    "retain_loader = filter_loaders(loaders, class_name, blcd_batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retain_input = next(iter(retain_loader))\n",
    "r_input_tensor, r_label_tensor = retain_input[0].to(device), retain_input[1].to(device)\n",
    "forget_input = next(iter(forget_loader))\n",
    "f_input_tensor, f_label_tensor = forget_input[0].to(device), forget_input[1].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking residues of the input after layer : Linear(in_features=128, out_features=9, bias=True)\n",
      "Checking residues of the input after layer : Linear(in_features=128, out_features=9, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model.zero_grad()\n",
    "r_input_tensor.requires_grad = True\n",
    "retain_dict = get_activations(model, r_input_tensor, -1, verbose=True)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "loss = criterion(retain_dict['output'], r_label_tensor)\n",
    "loss.backward()\n",
    "\n",
    "r_grads = []\n",
    "for param in model.parameters():\n",
    "    r_grads.append(param.grad)\n",
    "\n",
    "model.zero_grad()\n",
    "f_input_tensor.requires_grad = True\n",
    "forget_dict = get_activations(model, f_input_tensor, -1, verbose=True)\n",
    "\n",
    "sftmax = torch.exp(forget_dict['output']).mean(dim=0)\n",
    "activations = retain_dict['activations'].detach()\n",
    "\n",
    "activations_dict = {}\n",
    "for idx, label in enumerate(r_label_tensor):\n",
    "    label = int(label.item())  # Assurez-vous que le label est utilisable comme clÃ©\n",
    "    if label not in activations_dict.keys():\n",
    "        activations_dict[label] = {}\n",
    "        activations_dict[label]['activation'] = activations[idx, :].clone()\n",
    "        activations_dict[label]['count'] = 1\n",
    "    else:\n",
    "        activations_dict[label]['activation'] += activations[idx, :]\n",
    "        activations_dict[label]['count'] += 1\n",
    "\n",
    "target = 0\n",
    "for key, dval in activations_dict.items():\n",
    "    ikey = key - 1 * (key > class_num)\n",
    "    target += sftmax[ikey] * dval['activation'] / dval['count']\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "loss = criterion(torch.mean(forget_dict['activations'], dim=0), target)\n",
    "loss.backward()\n",
    "\n",
    "f_grads = []\n",
    "for param in model.parameters():\n",
    "    f_grads.append(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couche de taille torch.Size([32, 1, 3, 3]) potentiellement modifiable : 195\n",
      "couche de taille torch.Size([32]) potentiellement modifiable : 20\n",
      "couche de taille torch.Size([64, 32, 3, 3]) potentiellement modifiable : 9873\n",
      "couche de taille torch.Size([64]) potentiellement modifiable : 44\n",
      "couche de taille torch.Size([128, 3136]) potentiellement modifiable : 40786\n",
      "couche de taille torch.Size([128]) potentiellement modifiable : 22\n",
      "couche de taille torch.Size([9, 128]) potentiellement modifiable : 282\n",
      "couche de taille torch.Size([9]) potentiellement modifiable : 4\n",
      "potentiellement modifiable : 51226 sur 421513 soit 12.152887336808117 %\n"
     ]
    }
   ],
   "source": [
    "ttot = 0\n",
    "tcount = 0\n",
    "for f_grad, r_grad in list(zip(f_grads, r_grads)):\n",
    "    size = f_grad.size()\n",
    "    mask = f_grad * r_grad > 0\n",
    "    count = int(torch.sum(mask))\n",
    "    print(f'couche de taille {size} potentiellement modifiable : {count}')\n",
    "    tcount += count\n",
    "    tot = torch.tensor(size).prod().item()\n",
    "    ttot += tot\n",
    "    \n",
    "print(f'potentiellement modifiable : {tcount} sur {ttot} soit {100 * tcount / ttot} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

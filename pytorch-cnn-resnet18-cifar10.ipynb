{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting ruff\n","  Downloading ruff-0.6.9-py3-none-macosx_11_0_arm64.whl.metadata (25 kB)\n","Downloading ruff-0.6.9-py3-none-macosx_11_0_arm64.whl (9.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: ruff\n","Successfully installed ruff-0.6.9\n"]}],"source":["!pip install ruff"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["mps\n"]}],"source":["# Importing Libraries\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchsummary import summary\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","device = \"mps\"\n","print(device)"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["from torchvision import transforms\n","import numpy as np\n","import torch\n","\n","# Returns a list of transformations when called\n","\n","class GetTransforms():\n","    '''Returns a list of transformations when type as requested amongst train/test\n","       Transforms('train') = list of transforms to apply on training data\n","       Transforms('test') = list of transforms to apply on testing data'''\n","\n","    def __init__(self):\n","        pass\n","\n","    def trainparams(self):\n","        train_transformations = [ #resises the image so it can be perfect for our model.\n","            transforms.RandomHorizontalFlip(), # FLips the image w.r.t horizontal axis\n","            transforms.RandomRotation((-7,7)),     #Rotates the image to a specified angel\n","            transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)), #Performs actions like zooms, change shear angles.\n","            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # Set the color params\n","            transforms.ToTensor(), # comvert the image to tensor so that it can work with torch\n","            transforms.Normalize((0.491, 0.482, 0.446), (0.247, 0.243, 0.261)) #Normalize all the images\n","            ]\n","\n","        return train_transformations\n","\n","    def testparams(self):\n","        test_transforms = [\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.491, 0.482, 0.446), (0.247, 0.243, 0.261))\n","        ]\n","        return test_transforms"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["from torchvision import datasets\n","from torchvision import transforms\n","\n","\n","transformations = GetTransforms()\n","train_transforms = transforms.Compose(transformations.trainparams())\n","test_transforms = transforms.Compose(transformations.testparams())\n","\n","\n","class GetCIFAR10_TrainData():\n","    def __init__(self, dir_name:str):\n","        self.dirname = dir_name\n","\n","    def download_train_data(self):\n","        return datasets.CIFAR10('./data', train=True, download=True, transform=train_transforms)\n","\n","    def download_test_data(self):\n","        return datasets.CIFAR10('./data', train=False, download=True, transform=test_transforms)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100.0%\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}],"source":["data = GetCIFAR10_TrainData(os.chdir(\"..\"))\n","trainset = data.download_train_data()\n","testset = data.download_test_data()\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=512,\n","                                          shuffle=True, num_workers=4)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=512,\n","                                         shuffle=False, num_workers=4)"]},{"cell_type":"markdown","metadata":{},"source":["# The Model - RESNET18\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class BasicBlock(nn.Module):\n","    expansion = 1\n","    \n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","\n","        DROPOUT = 0.1\n","\n","        self.conv1 = nn.Conv2d(\n","            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.dropout = nn.Dropout(DROPOUT)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n","                               stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.dropout = nn.Dropout(DROPOUT)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes),\n","                nn.Dropout(DROPOUT)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.dropout(self.bn1(self.conv1(x))))\n","        out = self.dropout(self.bn2(self.conv2(out)))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n","                               stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return F.log_softmax(out, dim=-1)\n","\n","\n","def ResNet18():\n","    return ResNet(BasicBlock, [2, 2, 2, 2])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Importing Model and printing Summary\n","model = ResNet18().to(device)\n","summary(model, input_size=(3,32,32))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","from torch import nn\n","import torch.nn\n","from torch.functional import F\n","import os\n","\n","\n","def model_training(model, device, train_dataloader, optimizer, train_acc, train_losses):\n","            \n","    model.train()\n","    pbar = tqdm(train_dataloader)\n","    correct = 0\n","    processed = 0\n","    running_loss = 0.0\n","\n","    for batch_idx, (data, target) in enumerate(pbar):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        y_pred = model(data)\n","        loss = F.nll_loss(y_pred, target)\n","        \n","\n","        train_losses.append(loss)\n","        loss.backward()\n","        optimizer.step()\n","\n","        pred = y_pred.argmax(dim=1, keepdim=True)\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","        processed += len(data)\n","        # print statistics\n","        running_loss += loss.item()\n","        pbar.set_description(desc=f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n","        train_acc.append(100*correct/processed)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import os\n","from torch.functional import F\n","\n","cwd = os.getcwd()\n","\n","def model_testing(model, device, test_dataloader, test_acc, test_losses, misclassified = []):\n","    \n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    class_correct = list(0. for i in range(10))\n","    class_total = list(0. for i in range(10))\n","    # label = 0\n","    classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","    \n","    with torch.no_grad():\n","\n","        for index, (data, target) in enumerate(test_dataloader):\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            pred = output.argmax(dim=1, keepdim=True)\n","            \n","            for d,i,j in zip(data, pred, target):\n","                if i != j:\n","                    misclassified.append([d.cpu(),i[0].cpu(),j.cpu()])\n","\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","    test_loss /= len(test_dataloader.dataset)\n","    test_losses.append(test_loss)\n","    \n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n","        test_loss, correct, len(test_dataloader.dataset),\n","        100. * correct / len(test_dataloader.dataset)))\n","    \n","    test_acc.append(100. * correct / len(test_dataloader.dataset))\n","    return misclassified"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Training the model\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.05, patience=2, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=True)\n","# scheduler = StepLR(optimizer, step_size=15, gamma=0.1)\n","\n","train_acc = []\n","train_losses = []\n","test_acc = []\n","test_losses = []\n","\n","EPOCHS = 40\n","\n","for i in range(EPOCHS):\n","    print(f'EPOCHS : {i}')\n","    model_training(model, device, trainloader, optimizer, train_acc, train_losses)\n","    scheduler.step(train_losses[-1])\n","    misclassified = model_testing(model, device, testloader, test_acc, test_losses)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig, axs = plt.subplots(2,2, figsize=(25,20))\n","\n","axs[0,0].set_title('Train Losses')\n","axs[0,1].set_title('Training Accuracy')\n","axs[1,0].set_title('Test Losses')\n","axs[1,1].set_title('Test Accuracy')\n","\n","axs[0,0].plot(train_losses)\n","axs[0,1].plot(train_acc)\n","axs[1,0].plot(test_losses)\n","axs[1,1].plot(test_acc)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":46718,"sourceId":3649,"sourceType":"competition"}],"dockerImageVersionId":30008,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":4}
